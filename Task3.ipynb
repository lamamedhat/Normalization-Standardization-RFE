{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a12418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c21dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:\\\\Users\\\\SOFT\\\\Desktop\\\\Machine learning tasks\\\\Norm_a_Scale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd366a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ffd099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  commission\n",
      "0      1         0.1\n",
      "1      0         5.0\n",
      "2      1         1.0\n",
      "3      1         0.0\n",
      "4      0         0.2\n",
      "5      2         9.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b909a1",
   "metadata": {},
   "source": [
    "# Normalization using MinMaxScaler( ) function\n",
    "in minmaxscaler its not important to delete the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26018b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.01111111]\n",
      " [0.         0.55555556]\n",
      " [0.5        0.11111111]\n",
      " [0.5        0.        ]\n",
      " [0.         0.02222222]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization using MinMaxScaler()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define minmaxscaler\n",
    "MI_MA_SC = MinMaxScaler()\n",
    "# fit -> to learn min and max \n",
    "# transform -> to train and transform the data \n",
    "scaled_data = MI_MA_SC.fit_transform(data)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d1828",
   "metadata": {},
   "source": [
    "# standardization using standardscaler( ) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1fc73d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24253563 -0.72757123]\n",
      " [-1.21267813  0.72757123]\n",
      " [ 0.24253563 -0.46030016]\n",
      " [ 0.24253563 -0.75726801]\n",
      " [-1.21267813 -0.69787444]\n",
      " [ 1.69774938  1.91544261]]\n"
     ]
    }
   ],
   "source": [
    "# standardization using standardScaler()\n",
    "#  range -1 , 1 \n",
    "#  remove the label column \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# define standard scaler\n",
    "st_sc = StandardScaler()\n",
    "# transform data\n",
    "scaled_dataset = st_sc.fit_transform(data)\n",
    "print(scaled_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32b653",
   "metadata": {},
   "source": [
    "# RFE (recursive feature elimination) Feature selection\n",
    "RFE works by searching for a subset of features by starting with all features in the training dataset and successfully removing features until the desired number remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4afd487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False False False False False]\n",
      " Ranking : [1 1 1 1 1 6 4 3 2 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "# X-> the training input samples\n",
    "# y-> the target values\n",
    "# the number of feature (columns) should be at least 5 \n",
    "# the default of n samples is 100\n",
    "# make_fried1 returns input sample(X) and output value (y)\n",
    "# n_feature = 10 -> means the number of columns = 10\n",
    "#  random_state = 0  -> it means don't make the output random , but make it appear in order way \n",
    "#  for example -> don't make it ' true false true true false' ,,,,,,, make it ' true true true  false false ' in order way\n",
    "\n",
    "X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "\n",
    "# estimator -> put in it the algorithm that we apply\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "# n_feature_to_select -> the number of features to select at the end of the process \n",
    "selector = RFE(estimator, n_features_to_select=5)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "# support_ is The mask of selected features.\n",
    "print(selector.support_)\n",
    "# array([ True,  True,  True,  True,  True, False, False, False, False , False])\n",
    "print(f\" Ranking : {selector.ranking_}\")\n",
    "\n",
    "# array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b31891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23f32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
